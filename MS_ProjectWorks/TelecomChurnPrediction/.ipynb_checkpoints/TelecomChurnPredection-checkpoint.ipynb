{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbef8f73-e183-4972-9ff1-0df761aed65e",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "## Term Project: Customer Churn Prediction for a Telecom Company\n",
    "### Karthika Vellingiri\n",
    "### 14 Feb 2025\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514394d-edca-4b63-83c9-25c52b712203",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center> \n",
    "\n",
    "## **Milestone 1:  Data Selection and EDA** \n",
    "</center>\n",
    "\n",
    "\n",
    "    \n",
    "### Step 1: Business Problem and Idea\n",
    "\n",
    "**Problem:**  \n",
    "Customer churn is a critical challenge for telecom companies, where retaining customers is more cost-effective than acquiring new ones. Understanding the factors driving churn allows companies to implement targeted retention strategies. This project aims to predict customer churn using customer demographic data, service usage, and customer support interactions, enabling proactive actions to retain high-risk customers and reduce churn rates.\n",
    "\n",
    "**Goal:**  \n",
    "The goal of this project is to predict customer churn in a telecom company based on various customer attributes (e.g., demographic data, service usage, account information). By building a predictive model, the company can focus on high-risk customers, offering them personalized retention offers before they decide to leave. The model should classify whether a customer will churn or not (binary classification: Yes/No).\n",
    "\n",
    "**Target for the Model:**  \n",
    "The target variable will be `Churn`, which will have two possible values:\n",
    "- **Yes:** The customer will churn (leave the service).\n",
    "- **No:** The customer will remain with the service.\n",
    "\n",
    "The model will use features such as:\n",
    "- **Customer demographic data:** Age, gender, etc.\n",
    "- **Account information:** Service type, payment method, tenure with the company.\n",
    "- **Usage data:** Number of calls made, data usage, etc.\n",
    "- **Customer support interactions:** Whether the customer has contacted support, complaints, etc.\n",
    "\n",
    "### Step 2: Locating the Data\n",
    "\n",
    "For this project, I will use the [Telco Customer Churn dataset from Kaggle](https://www.kaggle.com/datasets/jeanmidev/wa-fn-usec-telco-customer-churn) that contains various customer details and whether they churned.\n",
    "\n",
    "The dataset typically includes the following columns:\n",
    "- **CustomerID:** Unique identifier for each customer.\n",
    "- **Gender:** Customer gender (Male/Female).\n",
    "- **SeniorCitizen:** Whether the customer is a senior citizen.\n",
    "- **Partner:** Whether the customer has a partner (Yes/No).\n",
    "- **Dependents:** Whether the customer has dependents (Yes/No).\n",
    "- **Tenure:** Number of months the customer has been with the company.\n",
    "- **PhoneService:** Whether the customer has phone service (Yes/No).\n",
    "- **MultipleLines:** Whether the customer has multiple lines (Yes/No).\n",
    "- **InternetService:** Type of internet service the customer has (DSL/Fiber optic/None).\n",
    "- **OnlineSecurity:** Whether the customer has online security service (Yes/No).\n",
    "- **OnlineBackup:** Whether the customer has online backup service (Yes/No).\n",
    "- **DeviceProtection:** Whether the customer has device protection (Yes/No).\n",
    "- **TechSupport:** Whether the customer has tech support (Yes/No).\n",
    "- **StreamingTV:** Whether the customer has streaming TV service (Yes/No).\n",
    "- **StreamingMovies:** Whether the customer has streaming movies service (Yes/No).\n",
    "- **Contract:** Type of contract (Month-to-month, One year, Two year).\n",
    "- **PaperlessBilling:** Whether the customer has paperless billing (Yes/No).\n",
    "- **PaymentMethod:** Payment method (Electronic check, Mailed check, Bank transfer, Credit card).\n",
    "- **MonthlyCharges:** Monthly charges for the customer.\n",
    "- **TotalCharges:** Total charges for the customer.\n",
    "- **Churn:** Whether the customer has churned (Yes/No).\n",
    "\n",
    "\n",
    "### Step 3: Analysis Questions\n",
    "\n",
    "- Are senior citizens more likely to churn compared to non-senior customers, regardless of gender?  \n",
    "\n",
    "- Does a shorter tenure correlate with a higher likelihood of churn?  \n",
    "\n",
    "- Do customers with higher monthly charges churn more frequently than those with lower charges?  \n",
    "\n",
    "- Which type of internet service (Fiber optic, DSL, or None) has the highest churn rate?  \n",
    "\n",
    "### Step 4: Graphical Analysis\n",
    "\n",
    "1. **Customer Demographics Distribution (Gender & SeniorCitizen)**  \n",
    "   - **Graph Type:** Bar chart  \n",
    "   - **Insight:** We will explore the gender distribution of customers and analyze if a higher percentage of senior citizens tend to churn.\n",
    "\n",
    "2. **Tenure vs. Churn**  \n",
    "   - **Graph Type:** Box plot  \n",
    "   - **Insight:** Analyze whether customers with shorter tenure are more likely to churn. A shorter tenure could be associated with higher churn rates.\n",
    "\n",
    "3. **Monthly Charges Distribution by Churn**  \n",
    "   - **Graph Type:** Box plot  \n",
    "   - **Insight:** Explore whether higher monthly charges correlate with a higher likelihood of churn, as customers with high monthly costs may leave due to dissatisfaction.\n",
    "\n",
    "4. **Internet Service vs. Churn**  \n",
    "   - **Graph Type:** Stacked bar chart  \n",
    "   - **Insight:** Investigate whether the type of internet service (e.g., Fiber optic) influences the likelihood of churn.\n",
    "\n",
    "### Step 5: Code Implementation for Graphical Analysis\n",
    "\n",
    "#### Data Preprocessing :\n",
    "1. **Handling Missing Values:**  \n",
    "   - `TotalCharges` may contain non-numeric values or missing data, so we convert it to numeric and handle any errors by coercing them into NaNs.\n",
    "   - We fill missing values in the dataset using the mean of the columns (for simplicity, but more advanced imputation strategies can be used).\n",
    "\n",
    "2. **Categorical Encoding:**  \n",
    "   - The `Churn` column is mapped to binary values (1 for Yes, 0 for No), making it easier to work with in a machine learning model.\n",
    "\n",
    "\n",
    "The following code generates graphical analyses, providing insights into customer churn. These visualizations will help in formulating hypotheses, which can be further tested and refined using a predictive model in the later stages of the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e558ced-3f5c-4ee5-ba7f-88b05ae89030",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "# Suppressing warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset from local folder\n",
    "file_path = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove leading and trailing spaces in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Data Preprocessing\n",
    "# Handle missing values in 'TotalCharges' by converting it to numeric (coerce errors to NaN)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Fill missing values in numeric columns with the column mean\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "\n",
    "# Encode 'Churn' as binary values (1 for Yes, 0 for No)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "#### Step 3: Graphical Analysis ####\n",
    "\n",
    "# 1. Distribution of Churn (Bar chart)\n",
    "\n",
    "# Graph Type: Bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Churn', data=df, palette='pastel')\n",
    "plt.title('Distribution of Churn')\n",
    "plt.xlabel('Churn (1: Yes, 0: No)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1], labels=['No Churn', 'Churn'])\n",
    "\n",
    "plt.savefig(\"churn_distribution.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 2. Customer Demographics Distribution (Gender & SeniorCitizen)\n",
    "\n",
    "# Graph Type: Bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# Gender Distribution\n",
    "sns.countplot(x='gender', data=df, palette='muted', ax=axes[0])\n",
    "axes[0].set_title('Gender Distribution of Customers')\n",
    "axes[0].set_xlabel('Gender')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# SeniorCitizen Distribution\n",
    "sns.countplot(x='SeniorCitizen', data=df, palette='coolwarm', ax=axes[1])\n",
    "axes[1].set_title('Senior Citizen Distribution of Customers')\n",
    "axes[1].set_xlabel('Senior Citizen (0: No, 1: Yes)')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Tenure vs. Churn (Box plot)\n",
    "\n",
    "# Graph Type: Box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Churn', y='tenure', data=df, palette='coolwarm')\n",
    "plt.title('Tenure vs. Churn')\n",
    "plt.xlabel('Churn (1: Yes, 0: No)')\n",
    "plt.ylabel('Tenure (Months)')\n",
    "\n",
    "plt.savefig(\"Tenure_distribution.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 4. Monthly Charges Distribution by Churn (Box plot)\n",
    "\n",
    "# Graph Type: Box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Churn', y='MonthlyCharges', data=df, palette='Set2')\n",
    "plt.title('Monthly Charges Distribution by Churn')\n",
    "plt.xlabel('Churn (1: Yes, 0: No)')\n",
    "plt.ylabel('Monthly Charges')\n",
    "\n",
    "plt.savefig(\"MonthlyCharges_Distribution.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 5. Internet Service vs. Churn (Stacked bar chart)\n",
    "\n",
    "# Graph Type: Stacked bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "internet_churn = df.groupby(['InternetService', 'Churn']).size().unstack().fillna(0)\n",
    "internet_churn.plot(kind='bar', stacked=True, color=['red', 'green'], figsize=(10, 6))\n",
    "plt.title('Internet Service vs. Churn')\n",
    "plt.xlabel('Internet Service Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['No Churn', 'Churn'])\n",
    "\n",
    "plt.savefig(\"InternetService_vs_Churn.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa8791-3405-4eba-9b9c-a1020814a8ce",
   "metadata": {},
   "source": [
    "\n",
    "### Overview of Insights from Graphical Analysis\n",
    "\n",
    "1. **Customer Demographics (Gender & Senior Citizens):**  \n",
    "   - Gender distribution shows a nearly equal number of male and female customers, indicating that churn is not heavily influenced by gender.  \n",
    "   - Senior citizens represent a smaller proportion of the customer base, but their churn patterns might warrant closer examination.  \n",
    "\n",
    "2. **Tenure vs. Churn:**  \n",
    "   - Customers with shorter tenures are more likely to churn, highlighting the importance of focusing on retention strategies for newer customers.  \n",
    "\n",
    "3. **Monthly Charges Distribution by Churn:**  \n",
    "   - Customers with higher monthly charges show a higher likelihood of churn, suggesting that pricing could be a critical factor driving customer dissatisfaction.  \n",
    "\n",
    "4. **Internet Service vs. Churn:**  \n",
    "   - The stacked bar chart reveals notable differences in churn rates across different types of internet services. For instance, customers using fiber optic services exhibit higher churn rates compared to those using DSL or no internet service, potentially due to perceived cost or service issues.  \n",
    "\n",
    "These insights highlight key factors like tenure, monthly charges, and internet service type as significant contributors to customer churn. Addressing these areas can guide targeted strategies to reduce churn and improve customer retention.\n",
    "\n",
    "### Conclusion:\n",
    "These visualizations offer key insights into customer behavior and their relationship with churn. For instance, the **Tenure vs. Churn** graph helps identify whether long-term customers are less likely to churn, while the **Monthly Charges Distribution by Churn** graph sheds light on whether customers with higher monthly charges are more likely to leave. These insights play a vital role in shaping strategies to improve customer retention and reduce churn.\n",
    "\n",
    "The analysis of these graphs establishes a solid groundwork for developing hypotheses about customer churn, which can be validated using predictive models in the subsequent stages of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804c723-c53e-47b7-ade2-7760fcb36852",
   "metadata": {},
   "source": [
    "<center> \n",
    "\n",
    "## **Milestone 2: Data Preparation** \n",
    "</center>\n",
    "\n",
    "\n",
    "**Goal:**\n",
    "The goal of this milestone is to prepare the dataset for modeling by handling missing data, creating new features, encoding categorical variables, and standardizing numerical features. This ensures that the data is in the right format and scale for the models we plan to use in subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03effc18-aae1-4eda-aaf1-f07c19b83947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loaded the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Local\\Temp\\ipykernel_18888\\1473398377.py:6: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Trimmed spaces from column names\n",
      "Step 3: Dropped 'customerID' column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Converted 'TotalCharges' to numeric, coercing errors to NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1840.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>820.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1949.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>301.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3046.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3487.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Filled missing values in 'TotalCharges' with column mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Local\\Temp\\ipykernel_18888\\1473398377.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TotalCharges'].fillna(df['TotalCharges'].mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1840.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Encoded 'Churn' as binary (1 for Yes, 0 for No)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: Created 'AvgMonthlySpend'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>tenure</th>\n",
       "      <th>AvgMonthlySpend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.85</td>\n",
       "      <td>1</td>\n",
       "      <td>29.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889.50</td>\n",
       "      <td>34</td>\n",
       "      <td>55.573529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.15</td>\n",
       "      <td>2</td>\n",
       "      <td>54.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1840.75</td>\n",
       "      <td>45</td>\n",
       "      <td>40.905556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.65</td>\n",
       "      <td>2</td>\n",
       "      <td>75.825000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: Created 'TenureGroup'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>TenureGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>24-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>36-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: Dropped 'tenure' column\n",
      "Step 10: Identified categorical and numerical columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Categorical Columns</th>\n",
       "      <th>Numerical Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>InternetService</td>\n",
       "      <td>MonthlyCharges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Contract</td>\n",
       "      <td>TotalCharges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PaymentMethod</td>\n",
       "      <td>AvgMonthlySpend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TenureGroup</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11: Defined preprocessing steps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Transformation Step</th>\n",
       "      <th>Applied To</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>MonthlyCharges, TotalCharges, AvgMonthlySpend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OneHotEncoder</td>\n",
       "      <td>InternetService, Contract, PaymentMethod, TenureGroup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12: Created a preprocessing pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pipeline Step</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Preprocessor</td>\n",
       "      <td>Applies StandardScaler to numerical features and OneHotEncoder to categorical features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13: Applied transformations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__MonthlyCharges</th>\n",
       "      <th>num__TotalCharges</th>\n",
       "      <th>num__AvgMonthlySpend</th>\n",
       "      <th>cat__InternetService_Fiber optic</th>\n",
       "      <th>cat__InternetService_No</th>\n",
       "      <th>cat__Contract_One year</th>\n",
       "      <th>cat__Contract_Two year</th>\n",
       "      <th>cat__PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>cat__PaymentMethod_Electronic check</th>\n",
       "      <th>cat__PaymentMethod_Mailed check</th>\n",
       "      <th>cat__TenureGroup_12-24</th>\n",
       "      <th>cat__TenureGroup_24-36</th>\n",
       "      <th>cat__TenureGroup_36-48</th>\n",
       "      <th>cat__TenureGroup_48-60</th>\n",
       "      <th>cat__TenureGroup_60+</th>\n",
       "      <th>cat__TenureGroup_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.160323</td>\n",
       "      <td>-0.994971</td>\n",
       "      <td>-1.151302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.259629</td>\n",
       "      <td>-0.173876</td>\n",
       "      <td>-0.301458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.362660</td>\n",
       "      <td>-0.960399</td>\n",
       "      <td>-0.350966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.746535</td>\n",
       "      <td>-0.195400</td>\n",
       "      <td>-0.786053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197365</td>\n",
       "      <td>-0.941193</td>\n",
       "      <td>0.367602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14: Combined transformed features with 'Churn'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__MonthlyCharges</th>\n",
       "      <th>num__TotalCharges</th>\n",
       "      <th>num__AvgMonthlySpend</th>\n",
       "      <th>cat__InternetService_Fiber optic</th>\n",
       "      <th>cat__InternetService_No</th>\n",
       "      <th>cat__Contract_One year</th>\n",
       "      <th>cat__Contract_Two year</th>\n",
       "      <th>cat__PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>cat__PaymentMethod_Electronic check</th>\n",
       "      <th>cat__PaymentMethod_Mailed check</th>\n",
       "      <th>cat__TenureGroup_12-24</th>\n",
       "      <th>cat__TenureGroup_24-36</th>\n",
       "      <th>cat__TenureGroup_36-48</th>\n",
       "      <th>cat__TenureGroup_48-60</th>\n",
       "      <th>cat__TenureGroup_60+</th>\n",
       "      <th>cat__TenureGroup_nan</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.160323</td>\n",
       "      <td>-0.994971</td>\n",
       "      <td>-1.151302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.259629</td>\n",
       "      <td>-0.173876</td>\n",
       "      <td>-0.301458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.362660</td>\n",
       "      <td>-0.960399</td>\n",
       "      <td>-0.350966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.746535</td>\n",
       "      <td>-0.195400</td>\n",
       "      <td>-0.786053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197365</td>\n",
       "      <td>-0.941193</td>\n",
       "      <td>0.367602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16: Saved the processed dataset as 'telco_churn_prepared.csv'\n",
      "Preview of the saved dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__MonthlyCharges</th>\n",
       "      <th>num__TotalCharges</th>\n",
       "      <th>num__AvgMonthlySpend</th>\n",
       "      <th>cat__InternetService_Fiber optic</th>\n",
       "      <th>cat__InternetService_No</th>\n",
       "      <th>cat__Contract_One year</th>\n",
       "      <th>cat__Contract_Two year</th>\n",
       "      <th>cat__PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>cat__PaymentMethod_Electronic check</th>\n",
       "      <th>cat__PaymentMethod_Mailed check</th>\n",
       "      <th>cat__TenureGroup_12-24</th>\n",
       "      <th>cat__TenureGroup_24-36</th>\n",
       "      <th>cat__TenureGroup_36-48</th>\n",
       "      <th>cat__TenureGroup_48-60</th>\n",
       "      <th>cat__TenureGroup_60+</th>\n",
       "      <th>cat__TenureGroup_nan</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.160323</td>\n",
       "      <td>-0.994971</td>\n",
       "      <td>-1.151302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.259629</td>\n",
       "      <td>-0.173876</td>\n",
       "      <td>-0.301458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.362660</td>\n",
       "      <td>-0.960399</td>\n",
       "      <td>-0.350966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.746535</td>\n",
       "      <td>-0.195400</td>\n",
       "      <td>-0.786053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197365</td>\n",
       "      <td>-0.941193</td>\n",
       "      <td>0.367602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from IPython.core.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# **Data Preprocessing and Feature Engineering for Model Building**\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "file_path = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Step 1: Loaded the dataset\")\n",
    "display(HTML(df.head().to_html()))\n",
    "\n",
    "# Step 2: Remove leading and trailing spaces in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"Step 2: Trimmed spaces from column names\")\n",
    "\n",
    "# Step 3: Drop unnecessary features\n",
    "df.drop(columns=['customerID'], inplace=True)\n",
    "print(\"Step 3: Dropped 'customerID' column\")\n",
    "display(HTML(df.head().to_html()))\n",
    "\n",
    "# Step 4: Convert 'TotalCharges' to numeric, handling errors\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "print(\"Step 4: Converted 'TotalCharges' to numeric, coercing errors to NaN\")\n",
    "display(HTML(df[['TotalCharges']].head(10).to_html()))\n",
    "\n",
    "# Step 5: Handle missing values in 'TotalCharges'\n",
    "df['TotalCharges'].fillna(df['TotalCharges'].mean(), inplace=True)\n",
    "print(\"Step 5: Filled missing values in 'TotalCharges' with column mean\")\n",
    "display(HTML(df[['TotalCharges']].head().to_html()))\n",
    "\n",
    "# Step 6: Encode 'Churn' as binary values\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "print(\"Step 6: Encoded 'Churn' as binary (1 for Yes, 0 for No)\")\n",
    "display(HTML(df[['Churn']].head().to_html()))\n",
    "\n",
    "# **Feature Engineering**\n",
    "\n",
    "# Step 7: Create a new feature: Average Monthly Spend\n",
    "df['AvgMonthlySpend'] = df['TotalCharges'] / df['tenure']\n",
    "df.loc[df['tenure'] == 0, 'AvgMonthlySpend'] = 0  \n",
    "print(\"Step 7: Created 'AvgMonthlySpend'\")\n",
    "display(HTML(df[['TotalCharges', 'tenure', 'AvgMonthlySpend']].head().to_html()))\n",
    "\n",
    "# Step 8: Bin 'tenure' into categories\n",
    "tenure_bins = [0, 12, 24, 36, 48, 60, np.inf]\n",
    "tenure_labels = ['0-12', '12-24', '24-36', '36-48', '48-60', '60+']\n",
    "df['TenureGroup'] = pd.cut(df['tenure'], bins=tenure_bins, labels=tenure_labels)\n",
    "print(\"Step 8: Created 'TenureGroup'\")\n",
    "display(HTML(df[['tenure', 'TenureGroup']].head().to_html()))\n",
    "\n",
    "# Step 9: Drop the original 'tenure' column\n",
    "df.drop(columns=['tenure'], inplace=True)\n",
    "print(\"Step 9: Dropped 'tenure' column\")\n",
    "\n",
    "# Step 10: Identify categorical and numerical columns\n",
    "categorical_cols = ['InternetService', 'Contract', 'PaymentMethod', 'TenureGroup']\n",
    "numerical_cols = ['MonthlyCharges', 'TotalCharges', 'AvgMonthlySpend']\n",
    "print(\"Step 10: Identified categorical and numerical columns\")\n",
    "\n",
    "# Create a DataFrame to display the identified column types\n",
    "column_types_df = pd.DataFrame({\n",
    "    \"Categorical Columns\": categorical_cols + [\"\"] * (max(len(numerical_cols) - len(categorical_cols), 0)),\n",
    "    \"Numerical Columns\": numerical_cols + [\"\"] * (max(len(categorical_cols) - len(numerical_cols), 0))\n",
    "})\n",
    "# Display the column types in a table format\n",
    "display(HTML(column_types_df.to_html(index=False)))\n",
    "\n",
    "# **Data Transformation and Scaling**\n",
    "\n",
    "# Step 11: Define preprocessing steps\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_cols),\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols)\n",
    "])\n",
    "print(\"Step 11: Defined preprocessing steps\")\n",
    "preprocessing_summary = pd.DataFrame({\n",
    "    \"Transformation Step\": [\"StandardScaler\", \"OneHotEncoder\"],\n",
    "    \"Applied To\": [\", \".join(numerical_cols), \", \".join(categorical_cols)]\n",
    "})\n",
    "display(HTML(preprocessing_summary.to_html(index=False)))\n",
    "\n",
    "\n",
    "# Step 12: Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "print(\"Step 12: Created a preprocessing pipeline\")\n",
    "\n",
    "# Display pipeline summary\n",
    "pipeline_summary = pd.DataFrame({\n",
    "    \"Pipeline Step\": [\"Preprocessor\"],\n",
    "    \"Description\": [\"Applies StandardScaler to numerical features and OneHotEncoder to categorical features\"]\n",
    "})\n",
    "display(HTML(pipeline_summary.to_html(index=False)))\n",
    "\n",
    "# Step 13: Transform the dataset\n",
    "df_transformed = pd.DataFrame(pipeline.fit_transform(df), columns=pipeline.named_steps['preprocessor'].get_feature_names_out())\n",
    "print(\"Step 13: Applied transformations\")\n",
    "display(HTML(df_transformed.head().to_html()))\n",
    "\n",
    "# **Final Data Preparation**\n",
    "\n",
    "# Step 14: Concatenate transformed data with the target variable\n",
    "final_df = pd.concat([df_transformed, df[['Churn']].reset_index(drop=True)], axis=1)\n",
    "print(\"Step 14: Combined transformed features with 'Churn'\")\n",
    "display(HTML(final_df.head().to_html()))\n",
    "\n",
    "# Step 15: Check for NaN or infinite values before saving\n",
    "if final_df.isna().sum().sum() > 0 or np.isinf(final_df).sum().sum() > 0:\n",
    "    print(\"Warning: NaN or infinite values detected in the final dataset.\")\n",
    "else:\n",
    "    # Save the processed dataset\n",
    "    final_df.to_csv(\"telco_churn_prepared.csv\", index=False)\n",
    "    print(\"Step 16: Saved the processed dataset as 'telco_churn_prepared.csv'\")\n",
    "    print(\"Preview of the saved dataset:\")\n",
    "    display(HTML(final_df.head(5).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5fadd4-b44c-4b9a-a35c-572abb9a6a83",
   "metadata": {},
   "source": [
    "### **Overview:**\n",
    "\n",
    "1. **Data Loading:**\n",
    "   - The dataset is loaded into a DataFrame.  \n",
    "   - This is the initial step to bring the data into a manageable format for further processing.\n",
    "\n",
    "2. **Cleaning Column Names:**\n",
    "   - Column names are cleaned by stripping any leading or trailing spaces using `df.columns.str.strip()`.  \n",
    "   - This ensures no issues arise when referencing columns later, particularly if spaces are mistakenly included in column names.\n",
    "\n",
    "3. **Dropping Unnecessary Features:**\n",
    "   - The `customerID` column is dropped using `df.drop(columns=['customerID'])`.  \n",
    "   - The `customerID` is a unique identifier and does not carry predictive power for the churn prediction task. Removing it helps reduce dimensionality and noise in the dataset.\n",
    "\n",
    "4. **Handling Missing Data in `TotalCharges`:**\n",
    "   - The `TotalCharges` column is converted to numeric using `pd.to_numeric()` with `errors='coerce'` to handle invalid values.  \n",
    "   - Any invalid values that cannot be converted to numeric will become `NaN`. This step ensures that `TotalCharges` is in the correct numeric format.\n",
    "\n",
    "5. **Filling Missing Values in `TotalCharges`:**\n",
    "   - Missing values in the `TotalCharges` column are filled with the column mean using `df['TotalCharges'].fillna()`.  \n",
    "   - This ensures data integrity and avoids issues with missing values while maintaining consistency in the dataset.\n",
    "\n",
    "6. **Encoding Categorical Variables (`Churn`):**\n",
    "   - The `Churn` column is encoded as binary values (1 for Yes, 0 for No) using `df['Churn'].map({'Yes': 1, 'No': 0})`.  \n",
    "   - Machine learning models require numerical inputs, so encoding categorical variables into binary numerical values makes them suitable for modeling.\n",
    "\n",
    "7. **Feature Engineering - Creating `AvgMonthlySpend`:**\n",
    "   - A new feature, `AvgMonthlySpend`, is created by dividing `TotalCharges` by `tenure`. If `tenure` is 0, the value of `AvgMonthlySpend` is set to 0 to avoid division by zero.  \n",
    "   - This feature represents how much a customer spends on average each month, providing useful context about customer behavior and likely predicting churn.\n",
    "\n",
    "8. **Binning the `tenure` Feature into `TenureGroup`:**\n",
    "   - The `tenure` column is binned into categories using `pd.cut()` to create a new feature `TenureGroup`.  \n",
    "   - The bins represent customer tenure ranges (e.g., 0-12 months, 12-24 months, etc.).  \n",
    "   - Grouping customers into tenure ranges provides insights into churn patterns and behavior, as newer customers might have different churn behavior than long-term ones.\n",
    "\n",
    "9. **Dropping the Original `tenure` Column:**\n",
    "   - The original `tenure` column is dropped using `df.drop(columns=['tenure'])` after creating the `TenureGroup` feature.  \n",
    "   - The `tenure` column is no longer needed since it has been transformed into a categorical variable, which reduces redundancy and improves model efficiency.\n",
    "\n",
    "10. **Identifying Categorical and Numerical Features:**\n",
    "   - Categorical features (`InternetService`, `Contract`, `PaymentMethod`, `TenureGroup`) and numerical features (`MonthlyCharges`, `TotalCharges`, `AvgMonthlySpend`) are identified.  \n",
    "   - Knowing which columns are categorical and which are numerical allows for the correct application of transformations, such as standardizing numerical values and one-hot encoding categorical features.\n",
    "\n",
    "11. **Defining Preprocessing Steps:**\n",
    "   - A `ColumnTransformer` is defined to apply standardization (`StandardScaler`) to numerical features and one-hot encoding (`OneHotEncoder`) to categorical features.  \n",
    "   - This ensures the correct transformation is applied to each type of feature in preparation for model training.\n",
    "\n",
    "12. **Creating the Preprocessing Pipeline:**\n",
    "   - A `Pipeline` is created to apply the preprocessing steps. Using a pipeline ensures that all preprocessing steps are applied sequentially and consistently, helping avoid errors and improving reproducibility.\n",
    "\n",
    "13. **Applying Transformations to the Dataset:**\n",
    "   - The dataset is transformed by applying the preprocessing steps to the original data using `pipeline.fit_transform()`, which prepares the features for the model.  \n",
    "   - This step ensures that all features are appropriately scaled, encoded, and ready for machine learning algorithms.\n",
    "\n",
    "14. **Combining Transformed Features with Target Variable:**\n",
    "   - The transformed features are combined with the target variable `Churn` using `pd.concat()`.  \n",
    "   - The target variable is essential for model training, so it must be included in the final dataset for modeling.\n",
    "\n",
    "15. **Checking for NaN or Infinite Values:**\n",
    "   - A check is performed to ensure there are no `NaN` or infinite values in the transformed dataset using `isna()` and `isinf()`.  \n",
    "   - It is essential to ensure that no missing or infinite values are present in the final dataset, as they can lead to errors during model training.\n",
    "\n",
    "16. **Saving the Processed Dataset:**\n",
    "   - If there are no `NaN` or infinite values in the final dataset, it is saved as `telco_churn_prepared.csv` using `final_df.to_csv()`.  \n",
    "   - Saving the cleaned and transformed dataset ensures it is available for future modeling or further analysis without the need to repeat preprocessing steps.\n",
    "\n",
    "\n",
    "### **Outcome:**\n",
    "- The dataset has been cleaned, transformed, and enhanced with new features like `AvgMonthlySpend` and `TenureGroup`.\n",
    "- Missing data has been appropriately handled, categorical variables have been encoded, and numerical features have been standardized.\n",
    "- The final dataset is now ready for model training and evaluation, having undergone all necessary preprocessing steps.\n",
    "\n",
    "This process ensures that the data is clean, well-structured, and ready for the next phase: model building and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad6472-3475-43c5-a9d1-ab95178c30f9",
   "metadata": {},
   "source": [
    "<center> \n",
    "\n",
    "## **Milestone 3: Model Building and Evaluation** \n",
    "</center>\n",
    "\n",
    "\n",
    "**Goal:**\n",
    "The goal of this milestone is to choose an appropriate model for predicting customer churn based on the available features and the nature of the target variable (binary classification: Churn or No Churn).\n",
    "\n",
    "### Model Selection & Justification\n",
    "\n",
    "- **Model**: Logistic Regression\n",
    "  - **Why Logistic Regression**: Logistic Regression is a widely used algorithm for binary classification problems, which fits the churn prediction problem (where the target variable is either \"Churn\" or \"No Churn\"). It's interpretable, fast to train, and works well with a range of data types, especially when we have a relatively linear decision boundary.\n",
    "  \n",
    "- **Evaluation Metrics**:\n",
    "  - **Accuracy**: The percentage of correct predictions, but this metric can be misleading in imbalanced datasets, so we'll also look at other metrics.\n",
    "  - **Precision & Recall**: These metrics are especially important because they help balance the costs of false positives and false negatives, particularly in cases where the classes are imbalanced.\n",
    "  - **F1-Score**: The harmonic mean of precision and recall, useful when you need a balance between the two.\n",
    "  - **ROC AUC**: AUC gives a better idea of the model's performance across different thresholds, especially when classes are imbalanced.\n",
    "  - **Confusion Matrix**: Helps in understanding how well the model classifies both classes (Churn vs No Churn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae59322-f3f3-443c-9ea0-6191fd5c811d",
   "metadata": {},
   "source": [
    "### Process Summary\n",
    "\n",
    "#### Step 1: Load the Processed Dataset\n",
    "- Load the dataset `telco_churn_prepared.csv` into a DataFrame.\n",
    "\n",
    "#### Step 2: Split Data into Features (X) and Target (y)\n",
    "- Separate the features (X) and target variable (y). The target variable is 'Churn', and the features include all other columns.\n",
    "\n",
    "#### Step 3: Split the Dataset into Training and Testing Sets\n",
    "- Split the data into training (80%) and testing (20%) sets using `train_test_split`.\n",
    "\n",
    "#### Step 4: Initialize the Logistic Regression Model\n",
    "- Instantiate a `LogisticRegression` model with a random seed for reproducibility.\n",
    "\n",
    "#### Step 5: Train the Model\n",
    "- Fit the logistic regression model on the training data (X_train, y_train).\n",
    "\n",
    "#### Step 6: Make Predictions\n",
    "- Use the trained model to predict the target variable (`Churn`) for the testing data (X_test).\n",
    "\n",
    "#### Step 7: Evaluate the Model\n",
    "- **Step 7.1 (Accuracy):** Calculate the accuracy of the model using `accuracy_score`.\n",
    "- **Step 7.2 (Confusion Matrix):** Compute the confusion matrix and display it.\n",
    "- **Step 7.3 (Confusion Matrix Heatmap):** Plot the confusion matrix as a heatmap for better visualization.\n",
    "- **Step 7.4 (Classification Report):** Generate a classification report showing precision, recall, and F1-score.\n",
    "- **Step 7.5 (ROC AUC Score):** Calculate the ROC AUC score to assess model performance.\n",
    "- **Step 7.6 (ROC Curve):** Plot the ROC curve to visualize the trade-off between true positive and false positive rates.\n",
    "\n",
    "#### Step 8: Hyperparameter Tuning\n",
    "- **Step 8:** Define a parameter grid for tuning the regularization strength (`C`) of the logistic regression model.\n",
    "- Perform grid search using `GridSearchCV` to find the best hyperparameters through cross-validation.\n",
    "\n",
    "#### Step 8.1: Best Hyperparameters\n",
    "- Display the best hyperparameters obtained from the grid search.\n",
    "\n",
    "#### Step 8.2: Retrain the Model with Best Hyperparameters\n",
    "- Retrain the model using the best hyperparameters found during hyperparameter tuning.\n",
    "\n",
    "#### Step 9: Evaluate the Tuned Model\n",
    "- **Step 9.1 (Confusion Matrix for Tuned Model):** Compute and display the confusion matrix for the tuned model.\n",
    "- **Step 9.2 (Plot Confusion Matrix for Tuned Model):** Visualize the confusion matrix for the tuned model using a heatmap.\n",
    "- **Step 9.3 (Classification Report for Tuned Model):** Generate the classification report for the tuned model.\n",
    "- **Step 9.4 (ROC AUC Score for Tuned Model):** Calculate and display the ROC AUC score for the tuned model.\n",
    "- **Step 9.5 (ROC Curve for Tuned Model):** Plot the ROC curve for the tuned model.\n",
    "\n",
    "#### Step 10: Save the Trained Tuned Model\n",
    "- Save the trained and tuned model to a file (`churn_model.pkl`) using `joblib`.\n",
    "\n",
    "#### Step 11: Load the Trained Model\n",
    "- Load the saved model from the file to ensure it can be used later.\n",
    "\n",
    "#### Step 12: Print the Loaded Model\n",
    "- Display the loaded model to verify that it was correctly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee25f3-84a4-4be9-8d41-673101a2f060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Step 1: Load the processed dataset\n",
    "file_path = \"telco_churn_prepared.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Split the data into features (X) and target (y)\n",
    "X = df.drop(columns=['Churn'])  # Features\n",
    "y = df['Churn']  # Target variable\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "display(HTML(\"<h3>Data Split: 80% training and 20% testing</h3>\"))\n",
    "\n",
    "# Step 4: Initialize the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Step 5: Train the model\n",
    "model.fit(X_train, y_train)\n",
    "display(HTML(\"<h3>Model Training: Logistic Regression model trained</h3>\"))\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "\n",
    "# Step 7.1: Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "display(HTML(f\"<h4>Accuracy: {accuracy:.4f}</h4>\"))\n",
    "\n",
    "# Step 7.2: Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Not Churn', 'Churn'], columns=['Predicted Not Churn', 'Predicted Churn'])\n",
    "display(HTML(\"<h4>Confusion Matrix:</h4>\"))\n",
    "display(cm_df)\n",
    "\n",
    "# Step 7.3: Plot the Confusion Matrix as a Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Not Churn', 'Predicted Churn'], yticklabels=['Not Churn', 'Churn'])\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig(\"ConfusionMatrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# Step 7.4: Classification Report (Precision, Recall, F1-score)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "class_report_df = pd.DataFrame(class_report).transpose()\n",
    "display(HTML(\"<h4>Classification Report:</h4>\"))\n",
    "display(class_report_df)\n",
    "\n",
    "# Step 7.5: ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "display(HTML(f\"<h4>ROC AUC Score: {roc_auc:.4f}</h4>\"))\n",
    "\n",
    "# Step 7.6: ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"ROCCurve.png\")\n",
    "plt.show()\n",
    "\n",
    "# Step 8: Hyperparameter Tuning\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}  # Regularization strength for Logistic Regression\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 8.1: Best hyperparameters\n",
    "display(HTML(f\"<h4>Best Parameters: {grid_search.best_params_}</h4>\"))\n",
    "\n",
    "# Step 8.2: Retrain the model using the tuned hyperparameters (Logistic Regression with best `C`)\n",
    "tuned_model = grid_search.best_estimator_\n",
    "tuned_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Evaluate the tuned model\n",
    "y_pred_tuned = tuned_model.predict(X_test)\n",
    "display(HTML(\"<h3>Evaluation of the Tuned Model:</h3>\"))\n",
    "display(HTML(f\"<h4>Accuracy: {accuracy_score(y_test, y_pred_tuned):.4f}</h4>\"))\n",
    "\n",
    "# Step 9.1: Confusion Matrix for Tuned Model\n",
    "cm_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "cm_tuned_df = pd.DataFrame(cm_tuned, index=['Not Churn', 'Churn'], columns=['Predicted Not Churn', 'Predicted Churn'])\n",
    "display(HTML(\"<h4>Confusion Matrix for Tuned Model:</h4>\"))\n",
    "display(cm_tuned_df)\n",
    "\n",
    "# Step 9.2: Plot the Confusion Matrix for Tuned Model as a Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_tuned, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Not Churn', 'Predicted Churn'], yticklabels=['Not Churn', 'Churn'])\n",
    "plt.title('Confusion Matrix Heatmap for Tuned Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig(\"ConfusionMatrix_Tuned.png\")\n",
    "plt.show()\n",
    "\n",
    "# Step 9.3: Classification Report for Tuned Model\n",
    "class_report_tuned = classification_report(y_test, y_pred_tuned, output_dict=True)\n",
    "class_report_tuned_df = pd.DataFrame(class_report_tuned).transpose()\n",
    "display(HTML(\"<h4>Classification Report for Tuned Model:</h4>\"))\n",
    "display(class_report_tuned_df)\n",
    "\n",
    "# Step 9.4: ROC AUC Score for Tuned Model\n",
    "display(HTML(f\"<h4>ROC AUC Score for Tuned Model: {roc_auc_score(y_test, tuned_model.predict_proba(X_test)[:, 1]):.4f}</h4>\"))\n",
    "\n",
    "# Step 9.5: ROC Curve for Tuned Model\n",
    "fpr_tuned, tpr_tuned, thresholds_tuned = roc_curve(y_test, tuned_model.predict_proba(X_test)[:, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_tuned, tpr_tuned, color='green', label=f'Tuned Model ROC Curve (AUC = {roc_auc_score(y_test, tuned_model.predict_proba(X_test)[:, 1]):.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Tuned Logistic Regression Model')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"ROCCurve_Tuned.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Step 10: Save the trained tuned model\n",
    "joblib.dump(tuned_model, 'churn_model.pkl')\n",
    "display(HTML(\"<h4>Model Saved: Tuned model saved as 'churn_model.pkl'</h4>\"))\n",
    "\n",
    "# Step 11: Load the trained model\n",
    "loaded_model = joblib.load('churn_model.pkl')\n",
    "\n",
    "# Step 12: Print the loaded model\n",
    "display(HTML(\"<h4>Loaded Model:</h4>\"))\n",
    "display(loaded_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6b5e2-6f0d-4507-bdb8-4fc8f224b418",
   "metadata": {},
   "source": [
    "## Interpretation of the results from both the baseline logistic regression model and the tuned logistic regression model:\n",
    "\n",
    "### Baseline Model Results\n",
    "- **Accuracy: 0.8070**: The baseline model correctly predicted 80.7% of the cases. This is a good starting point.\n",
    "  \n",
    "- **Confusion Matrix:**\n",
    "  - True negatives (Not Churn correctly predicted): 955\n",
    "  - False positives (Predicted Churn when its actually Not Churn): 81\n",
    "  - False negatives (Predicted Not Churn when its actually Churn): 191\n",
    "  - True positives (Churn correctly predicted): 182\n",
    "  \n",
    "- **Classification Report:**\n",
    "  - **Precision (0 class, Not Churn):** 0.8333  The model correctly identifies 83.33% of the times when it predicts someone will not churn.\n",
    "  - **Recall (0 class, Not Churn):** 0.9218  92.18% of the actual \"Not Churn\" cases were correctly identified.\n",
    "  - **F1-Score (0 class, Not Churn):** 0.8753  This is the balance between precision and recall for \"Not Churn\".\n",
    "  \n",
    "  - **Precision (1 class, Churn):** 0.6920  69.20% of the times when it predicted churn, it was correct.\n",
    "  - **Recall (1 class, Churn):** 0.4879  The model correctly predicted 48.79% of actual churn cases.\n",
    "  - **F1-Score (1 class, Churn):** 0.5723  The balance of precision and recall for the \"Churn\" class is lower, indicating its harder for the model to correctly identify churn cases.\n",
    "  \n",
    "  - **ROC AUC Score: 0.8520**: The ROC AUC score indicates that the model has a strong ability to discriminate between the \"Not Churn\" and \"Churn\" classes. A score closer to 1 indicates good performance.\n",
    "\n",
    "### Tuned Model Results (After Hyperparameter Tuning)\n",
    "- **Best Parameters: {'C': 0.01}**: The tuned model uses a regularization strength of 0.01, which is a lower value, indicating that it tries to avoid overfitting by applying stronger regularization.\n",
    "  \n",
    "- **Accuracy: 0.8062**: The accuracy of the tuned model is very similar to the baseline (80.62% vs. 80.70%), indicating that the performance is stable even after hyperparameter tuning.\n",
    "\n",
    "- **Confusion Matrix for Tuned Model:**\n",
    "  - True negatives (Not Churn correctly predicted): 961\n",
    "  - False positives (Predicted Churn when its actually Not Churn): 75\n",
    "  - False negatives (Predicted Not Churn when its actually Churn): 198\n",
    "  - True positives (Churn correctly predicted): 175\n",
    "  \n",
    "- **Classification Report for Tuned Model:**\n",
    "  - **Precision (0 class, Not Churn):** 0.8292  The tuned model slightly improved its precision for \"Not Churn\" compared to the baseline.\n",
    "  - **Recall (0 class, Not Churn):** 0.9276  Recall is slightly better in the tuned model, meaning it did a slightly better job at identifying actual \"Not Churn\" cases.\n",
    "  - **F1-Score (0 class, Not Churn):** 0.8756  Slight improvement in the balance between precision and recall for \"Not Churn\".\n",
    "  \n",
    "  - **Precision (1 class, Churn):** 0.7000  The tuned model is better at identifying when a customer is predicted to churn compared to the baseline (69.20%).\n",
    "  - **Recall (1 class, Churn):** 0.4692  Recall has decreased slightly from the baseline (48.79%), meaning its predicting fewer churn cases correctly.\n",
    "  - **F1-Score (1 class, Churn):** 0.5618  F1 score slightly improved for churn prediction but is still lower than for \"Not Churn\".\n",
    "  \n",
    "  - **ROC AUC Score for Tuned Model: 0.8462**: The ROC AUC score for the tuned model is slightly lower than the baseline model (0.8520), but still indicates strong performance in distinguishing between the two classes.\n",
    "\n",
    "### Model Comparison\n",
    "- **Accuracy:** Both models have very similar accuracy (about 80.6%), meaning the hyperparameter tuning did not drastically change the overall performance.\n",
    "- **Precision and Recall for \"Churn\":** The tuned model has a slight improvement in precision (0.7000 vs. 0.6920) but a slight decrease in recall (0.4692 vs. 0.4879), meaning it is now slightly better at predicting when a customer will churn but worse at capturing all churn cases.\n",
    "- **ROC AUC:** The ROC AUC score for the tuned model is very similar to the baseline, indicating a similar ability to distinguish between the two classes.\n",
    "\n",
    "### Conclusion\n",
    "- The hyperparameter tuning (`C = 0.01`) improved precision for the \"Churn\" class and recall for the \"Not Churn\" class but resulted in a slight decrease in recall for the \"Churn\" class. \n",
    "- The model overall has very stable performance after tuning, and the changes may not be significant enough to make a large difference in predictive power.\n",
    "- **Next Steps:** Further experiment with other hyperparameters, or even try different algorithms like Random Forest or XGBoost is required to see if there are improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc956b06-6d94-4c42-bc11-67f0ab5f087d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
